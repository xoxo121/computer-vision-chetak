{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcb61bd-0867-4215-aad6-8a877fecdf46",
   "metadata": {},
   "source": [
    "**LANE DETECTION PROJECT**\n",
    "\n",
    "Rahul Vimalkanth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba01911-9dcc-4398-ac79-191839b4c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c290c06-8082-4861-b018-220ff2087f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a region of interest by masking other regions\n",
    "def create_roi(frame, vertices):\n",
    "    mask = np.zeros_like(frame)\n",
    "    cv.fillPoly(mask, [vertices], 255)\n",
    "    masked_img = cv.bitwise_and(frame, mask)\n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691db4bd",
   "metadata": {},
   "source": [
    "Canny Edge Detection Algorithm\n",
    "\n",
    "1. Noise Reduction: The first step is to reduce noise in the image using a Gaussian blur. This helps to smooth out the image and remove high-frequency noise, which can cause false edge detection.\n",
    "\n",
    "2. Gradient Calculation: Next, the gradient (rate of change) of pixel intensity at each point in the image is calculated. This is typically done using derivatives (such as the Sobel operator) to find the rate of change in pixel intensity in both the x and y directions.\n",
    "\n",
    "3. Edge Strength and Orientation: From the gradients, the edge strength (magnitude) and orientation (direction) are calculated for each pixel. The edge strength represents the rate of change in intensity, while the orientation indicates the direction of the gradient.\n",
    "\n",
    "4. Non-maximum Suppression: This step involves thinning the edges by suppressing all gradient values except for those that represent local maxima along the direction of the gradient. This helps to ensure that only the most significant edges are retained.\n",
    "\n",
    "5. Edge Hysteresis Thresholding: Finally, the edges are further refined by applying two thresholds: a high threshold (above which pixels are considered strong edges) and a low threshold (below which pixels are considered non-edges). Pixels with gradient magnitudes above the high threshold are considered strong edges, while pixels between the low and high thresholds are considered weak edges. Weak edges are retained only if they are connected to strong edges, forming continuous edge contours.\n",
    "\n",
    "The output of the Canny edge detection algorithm is a binary edge map where pixels corresponding to edges are set to white (255) and non-edge pixels are set to black (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e18b7-2b2e-44f8-897b-774374b1ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running canny edge detection\n",
    "def pre_process(img):\n",
    "    roi_vertices = np.array([(200, 700), (1100, 700), (750, 400), (550, 400)], np.int32)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    canny = cv.Canny(gray, 100, 200)\n",
    "    cropped = create_roi(canny, roi_vertices)\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081b289",
   "metadata": {},
   "source": [
    "cv.addWeighted()\n",
    "\n",
    "image: This is the first input image.\n",
    "\n",
    "line_image: This is the second input image.\n",
    "\n",
    "0.8: The weight (alpha) for the first image. It determines how much the first image contributes to the final result.\n",
    "\n",
    "1: The weight (beta) for the second image. It determines how much the second image contributes to the final result.\n",
    "\n",
    "0: The gamma value, which is an optional parameter. It controls the brightness of the output image.\n",
    "\n",
    "The resulting final_image will be a combination of the two input images, with the specified weights. Itâ€™s commonly used for overlaying one image on top of another, such as adding lines or annotations to an existing image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced79ea-d294-4c29-a8af-c60a874dcb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing lines on detected edges\n",
    "def draw_lines(img, lines):\n",
    "    img = np.copy(img)\n",
    "    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv.line(blank_image, (x1, y1), (x2, y2), (0, 0, 255), thickness=10)\n",
    "    img = cv.addWeighted(img, 0.8, blank_image, 1, 0.0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194e35e-0098-45c7-a6bb-03db9fc92eff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# capturing and displaying the video\n",
    "cap = cv.VideoCapture(\"Videos/Computer_Vision/highway_-_10364 (720p).mp4\")\n",
    "Video(\"Videos/Computer_Vision/highway_-_10364 (720p).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105e7fc",
   "metadata": {},
   "source": [
    "The Probabilistic Hough Line Transform is an improved version of the standard Hough Line Transform.\n",
    "It is used for detecting straight lines in an image.The probabilistic variant directly provides the endpoints of the detected line segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354cd0f",
   "metadata": {},
   "source": [
    "Adjusting the parameters of the Hough Line Transform can significantly impact the accuracy and robustness of lane detection.\n",
    "\n",
    "rho: Distance resolution of the accumulator in pixels. Decreasing rho increases the resolution, potentially detecting smaller lines, but it also increases computational load.\n",
    "\n",
    "theta: Angular resolution of the accumulator in radians. Smaller values allow for more precision but also increase computation.\n",
    "\n",
    "threshold: Minimum number of votes (intersections in Hough grid cell) required for a line to be detected. Increase to make detection stricter, reducing false positives, but be cautious not to filter out valid lines.\n",
    "\n",
    "minLineLength: Minimum length of a line (in pixels) to be considered a line. Increasing this value filters out shorter lines, reducing noise but potentially missing valid shorter lines.\n",
    "\n",
    "maxLineGap: Maximum allowed gap between line segments to be considered as a single line. Increasing this value allows for gapped lines to be connected, potentially detecting longer lines but also increasing the risk of merging unrelated segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be156d39",
   "metadata": {},
   "source": [
    "By using cap.set(cv.CAP_PROP_POS_FRAMES, 0), we ensure that if the video capture object reaches the end of the video (i.e., ret becomes False), it will reset the current position to the start of the video, allowing the video processing loop to continue capturing frames from the beginning. This ensures continuous looping through the video without interruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80257117-e1f0-46b7-9035-1c9d7a3e03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read() #reading the video\n",
    "    if not ret:\n",
    "        cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "    modified_img = pre_process(frame)\n",
    "    lines = cv.HoughLinesP(modified_img, rho=3, theta=np.pi/180, threshold=45, minLineLength=25, maxLineGap=35)\n",
    "    img = draw_lines(frame, lines)\n",
    "    cv.imshow('Lane Detection', img)\n",
    "    cv.imshow('Edge',modified_img)\n",
    "    \n",
    "    # Check for 'esc' key press to exit\n",
    "    key = cv.waitKey(10)\n",
    "    if key == 27:  \n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
